import re
import json
import psycopg2

host = 'localhost'  # Replace 'your_host' with the hostname or IP address of your CockroachDB node
port = '26257'  # Default CockroachDB port
user = 'root'  # Username
password = ''  # Password
database = 'defaultdb'  # Database name

# Establish a connection to CockroachDB
conn = psycopg2.connect(
    host=host,
    port=port,
    user=user,
    password=password,
    database=database
)

# Create a cursor object
cursor = conn.cursor()

schema_dict = [{
    "schema": "Pluto",
    "tables": ["Dettaglio_Sub_Contratto", "Cap", "Provincia"]
}, {
    "schema": "Niente",
    "tables": []
}]

def eliminate_after_world(text, word):
    index = text.lower().find(word.lower())
    if index != -1:
        return text[:index-1]
    else:
        return text

# Function to add underscore before capital letters
def add_underscore(string):
    result = ''
    for i in range(len(string)):  # Skip first character to avoid leading underscore
        if string[i].isupper():
            result += '_' + string[i]
        elif string[i].isnumeric():
            if string[i-1].isupper():
                result += '_' + string[i]
            else:
                result += string[i]
        else:
            result += string[i]

    if len(result) > 0:
        if result[0] == '_':
            result = result[1:]

        if result[1] == '_':
            result = result.replace('_', '')

    return result

all_fk_sql = ''
def parse_table_text(text):
    lines = text.split('\n')
    if lines[0].strip() == '':
        lines = lines[1:]
    table_name = re.search(r'\((.*?)\)', lines[0]).group(1)
    table_name = add_underscore(table_name)
    if lines[1].strip() == 'Field Name':
        # table_type = ''
        lines = lines[9:][::2]
    else:
        # table_type = lines[1].strip()
        lines = lines[11:][::2]

    required_list = []
    for i in range(1, len(lines)):
        if 'require' in lines[i].strip().lower() and 'null' in lines[i-1]:
            required_list.append(i)

        elif 'require' in lines[i].strip().lower() and 'null' not in lines[i-1]:
            lines[i] = 'NULL'

    for index in sorted(required_list, reverse=True):
        del lines[index]

    columns = []
    foreign_keys = []
    for i in range(0, len(lines)-3, 4):
        field_name = lines[i]
        field_name = field_name.strip()
        field_name = add_underscore(field_name)
        description = lines[i + 1]
        data_type = lines[i + 2]
        constraints = lines[i + 3]
        constraints = constraints.replace('PK', 'PRIMARY KEY')
        if 'FK' in constraints:
            for item in schema_dict:
                if table_name in item['tables']:
                    Schema_1 = item['schema']
                    break
                else:
                    Schema_1 = 'Pippo'

            for item in schema_dict:
                if '_'.join(field_name.split('_')[1:]) in item['tables']:
                    Schema_2 = item['schema']
                    break
                else:
                    Schema_2 = 'Pippo'

            foreign_keys.append({
                "table_name_1": table_name,
                "field_name_1": field_name,
                "Schema_1": Schema_1,
                "table_name_2": '_'.join(field_name.split('_')[1:]),
                "field_name_2": field_name.split('_')[0],
                "Schema_2": Schema_2
            })
        # constraints = constraints.replace('FK', 'FOREIGN KEY')
        constraints = constraints.replace('FK', '')
        constraints = constraints.lower().replace('identity', 'GENERATED BY DEFAULT AS IDENTITY (INCREMENT 1 MINVALUE 0 START 0)')
        constraints = constraints.replace('not Required', '')
        constraints = constraints.replace(',', '')
        if "pippo" in constraints.lower():
            constraints = 'NULL'

        if 'required' in constraints.lower():
            constraints = 'NULL'

        if 'enum' in constraints.lower():
            constraints = eliminate_after_world(constraints, 'enum')

        if '.' in constraints:
            constraints = constraints.replace('.', '')

        # Remove extra whitespace and replace 'null' with None

        description = description.strip()
        if field_name == 'Annullato':
            data_type = 'BOOLEAN'
            constraints = 'DEFAULT false NOT NULL'
        else:
            data_type = data_type.strip()
            constraints = constraints.strip()

        if data_type.lower() == 'varchar(max)':
            data_type = 'TEXT'

        if 'number' in data_type.lower():
            data_type = data_type.replace('number', 'decimal')

        if 'date' in data_type.lower():
            data_type = data_type.replace(data_type.lower(), 'timestamp')

        columns.append({
            "Field Name": field_name,
            "Description": description,
            "Data Type": data_type,
            "Constraints": constraints
        })

    SQL_FK = ''
    for fk in foreign_keys:
        SQL_FK += f'ALTER TABLE "{fk["Schema_1"]}".{fk["table_name_1"]} ADD FOREIGN KEY ({fk["field_name_1"]}) REFERENCES "{fk["Schema_2"]}".{fk["table_name_2"]} ({fk["field_name_2"]});\n'


    return {
        "table_name": table_name,
        # "table_type": table_type,
        "columns": columns
    }, SQL_FK
def filter_rows(file_path, output_path):
    with open(file_path, 'r', encoding='utf-8') as input_file, open(output_path, 'w', encoding='utf-8') as output_file:
        for line in input_file:
            if 'require' not in line.lower():
                output_file.write(line)

    return output_file

def read_text_file(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        text = file.read()

    table_descriptions = text.split('*****')
    tables = []
    all_fk_sql = ''
    for table_description in table_descriptions:
        if table_description.strip():
            tables.append(parse_table_text(table_description)[0])
            all_fk_sql += parse_table_text(table_description)[1]

    with open('pippo.txt', 'w') as file:
        # Write the new text to the file
        file.write(all_fk_sql)
    return tables

tables = read_text_file('Orders Management Entities.txt')


# Define the file path
file_path = "data.json"

for table in tables:
    for schema in schema_dict:
        if table['table_name'] in schema['tables']:
            Schema = schema['schema']
            break
        else:
            Schema = 'Pippo'
    SQL = ''
    SQL += f'CREATE TABLE "{Schema}".{table["table_name"]} (\n'
    for column in table['columns']:
        if 'FOREIGN KEY' in column['Constraints']:
            pass
            # SQL += f"    {column['Field Name']} {column['Data Type']} {column['Constraints'].replace('FOREIGN KEY', '')},\n"
            # reference_table = column['Field Name'].split('_')[0]
            # reference_column = '_'.join(column['Field Name'].split('_')[1:])
            # SQL += f'    CONSTRAINT fk_{table["table_name"]}_{column["Field Name"]} FOREIGN KEY ({column["Field Name"]}) REFERENCES "{Schema}".{reference_table} ({reference_column}),\n'
        else:
            SQL += f"    {column['Field Name']} {column['Data Type']} {column['Constraints']},\n"

    SQL = SQL[:-2] + '\n);\n\n'

    for column in table['columns']:
        SQL += f'COMMENT ON COLUMN "{Schema}".{table["table_name"]}.{column["Field Name"]} IS \'{column["Description"]}\';\n'

    SQL += '\n\n'
    SQL = SQL.replace('à', 'a').replace('è', 'e').replace('é', 'e').replace('ì', 'i').replace('ò', 'o').replace('ù', 'u')
    cursor.execute(SQL)

    print(SQL)
# Write the data to the JSON file

conn.commit()

# Close cursor and connection
cursor.close()
conn.close()
with open(file_path, "w", encoding='utf-8') as json_file:
    json.dump(tables, json_file, indent=4, ensure_ascii=False)



